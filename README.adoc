= Fractor: Function-driven Ractors framework

Fractor is a lightweight Ruby framework designed to simplify the process of
distributing computational work across multiple Ractors.

== Introduction

Fractor stands for *Function-driven Ractors framework*. It is a lightweight Ruby
framework designed to simplify the process of distributing computational work
across multiple Ractors (Ruby's actor-like concurrency model).

The primary goal of Fractor is to provide a structured way to define work,
process it in parallel using Ractors, and aggregate the results, while
abstracting away much of the boilerplate code involved in Ractor management and
communication.

== Installation

=== Using RubyGems

[source,sh]
----
gem install fractor
----

=== Using Bundler

Add this line to your application's Gemfile:

[source,ruby]
----
gem 'fractor'
----

And then execute:

[source,sh]
----
bundle install
----


=== Key concepts

* *Function-driven:* You define the core processing logic by subclassing
  `Fractor::Worker` and implementing the `process` method.

* *Parallel execution:* Work items are automatically distributed to available
  worker Ractors for concurrent processing.

* *Result aggregation:* The framework collects both successful results and
  errors from the workers.

* *Separation of concerns:* Keeps the framework logic (`fractor.rb`) separate
  from the client's specific implementation (`sample.rb`).

== Scope

This document describes the design, implementation, and usage of the Fractor
framework. It provides detailed information about the framework's components,
their interactions, and how to use them to implement parallel processing in Ruby
applications.

[bibliography]
== Normative references

* [[[ruby-ractor,Ruby Ractor Documentation]]], https://docs.ruby-lang.org/en/master/Ractor.html

== Terms and definitions

=== ractor

concurrent programming abstraction in Ruby that enables parallel execution
with thread safety

[.source]
<<ruby>>

=== worker

component that processes work items to produce work results

=== work item

unit of computation to be processed by a ractor

=== work result

result of processing a work item, either successful or an error

=== work item class

class that represents a work item, typically subclassing `Fractor::Work`

=== worker class

class that represents a worker, typically subclassing `Fractor::Worker`

=== wrapped ractor

component that manages a single ractor and its associated worker

=== supervisor

component that manages the pool of workers and distributes work items

=== result aggregator

component that collects and organizes work results from workers




== Core components

=== General

The Fractor framework consists of the following main classes, all residing
within the `Fractor` module.


=== Fractor::Worker

The abstract base class for defining how work should be processed.

Client code must subclass this and implement the `process(work)` method.

The `process` method receives a `Fractor::Work` object (or a subclass) and
should return a `Fractor::WorkResult` object.

=== Fractor::Work

The abstract base class for representing a unit of work.

Typically holds the input data needed by the `Worker`.

Client code should subclass this to define specific types of work items.

=== Fractor::WorkResult

A container object returned by the `Worker#process` method.

Holds either the successful `:result` of the computation or an `:error`
message if processing failed.

Includes a reference back to the original `:work` item.

Provides a `success?` method.

=== Fractor::ResultAggregator

Collects and stores all `WorkResult` objects generated by the workers.

Separates results into `results` (successful) and `errors` arrays.

=== Fractor::WrappedRactor

Manages an individual Ruby `Ractor`.

Instantiates the client-provided `Worker` subclass within the Ractor.

Handles receiving `Work` items, calling the `Worker#process` method, and
yielding `WorkResult` objects (or errors) back to the `Supervisor`.

=== Fractor::Supervisor

The main orchestrator of the framework.

Initializes and manages a pool of `WrappedRactor` instances.

Manages a `work_queue` of input data.

Distributes work items (wrapped in the client's `Work` subclass) to available
Ractors.

Listens for results and errors from Ractors using `Ractor.select`.

Uses `ResultAggregator` to store outcomes.

Handles graceful shutdown on `SIGINT` (Ctrl+C).



== Quick start

=== General

This quick start guide shows the minimum steps needed to get a simple parallel
execution working with Fractor.

=== Step 1: Create a minimal Work class

The Work class represents a unit of work to be processed by a Worker. It
encapsulates the input data needed for processing.

[source,ruby]
----
require 'fractor'

class MyWork < Fractor::Work
  # Store all properties in the input hash
  def initialize(value)
    super({ value: value })
  end

  # Accessor method for the stored value
  def value
    input[:value]
  end

  def to_s
    "MyWork: #{value}"
  end
end
----

A Work is instantiated with the input data it will process this way:

[source,ruby]
----
work_item = MyWork.new(42)
puts work_item.to_s  # Output: MyWork: 42
----


=== Step 2: Create a minimal Worker class

The Worker class defines the processing logic for work items. Each Worker
instance runs within its own Ractor and processes Work objects sent to it.

It must implement the `process(work)` method, which takes a Work object as
input and returns a `Fractor::WorkResult` object.

The `process` method should handle both successful processing and error
conditions.

[source,ruby]
----
class MyWorker < Fractor::Worker
  def process(work)
    # Your processing logic here
    result = work.input * 2

    # Return a success result
    Fractor::WorkResult.new(result: result, work: work)
  rescue => e
    # Return an error result if something goes wrong
    Fractor::WorkResult.new(error: e.message, work: work)
  end
end
----

The `process` method can perform any computation you need. In this example, it
multiplies the input by 2. If an error occurs, it catches the exception and
returns an error result.

=== Step 3: Set up and run the Supervisor

The Supervisor class orchestrates the entire framework, managing worker Ractors,
distributing work, and collecting results.

It initializes pools of Ractors, each running an instance of a Worker
class. The Supervisor handles the communication between the main thread and
the Ractors, including sending work items and receiving results.

The Supervisor also manages the work queue and the ResultAggregator, which
collects and organizes all results from the workers.

To set up the Supervisor, you specify worker pools, each containing a Worker class
and optionally the number of workers to create. If you don't specify `num_workers`,
Fractor will automatically detect the number of available processors on your system
and use that value. You can create multiple worker pools with different worker types
to handle different kinds of work. Each worker pool can process any type of Work
object that inherits from Fractor::Work.

[source,ruby]
----
# Create the supervisor with auto-detected number of workers
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker }  # Number of workers auto-detected
  ]
)

# Or explicitly specify the number of workers
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker, num_workers: 4 }  # Explicitly use 4 workers
  ]
)

# Add individual work items (instances of Work subclasses)
supervisor.add_work_item(MyWork.new(1))

# Add multiple work items
supervisor.add_work_items([
  MyWork.new(2),
  MyWork.new(3),
  MyWork.new(4),
  MyWork.new(5)
])

# You can add different types of Work objects to the same supervisor
supervisor.add_work_items([
  MyWork.new(6),
  OtherWork.new("data")
])

# Run the processing
supervisor.run

# Access results
puts "Results: #{supervisor.results.results.map(&:result)}"
puts "Errors: #{supervisor.results.errors.size}"
----

That's it! With these three simple steps, you have a working parallel processing
system using Fractor.


== Usage

=== Work class

==== Purpose and responsibilities

The `Fractor::Work` class represents a unit of work to be processed by a Worker.
Its primary responsibility is to encapsulate the input data needed for
processing.

==== Implementation requirements

At minimum, your Work subclass should:

. Inherit from `Fractor::Work`
. Pass the input data to the superclass constructor

[source,ruby]
----
class MyWork < Fractor::Work
  def initialize(input)
    super(input) # This stores input in @input
    # Add any additional initialization if needed
  end
end
----

==== Advanced usage

You can extend your Work class to include additional data or methods:

[source,ruby]
----
class ComplexWork < Fractor::Work
  attr_reader :options

  def initialize(input, options = {})
    super(input)
    @options = options
  end

  def high_priority?
    @options[:priority] == :high
  end

  def to_s
    "ComplexWork: #{@input} (#{@options[:priority]} priority)"
  end
end
----

[TIP]
====
====
* Keep Work objects lightweight and serializable since they will be passed
  between Ractors
* Implement a meaningful `to_s` method for better debugging
====
* Consider adding validation in the initializer to catch issues early
====

=== Worker class

==== Purpose and responsibilities

The `Fractor::Worker` class defines the processing logic for work items. Each
Worker instance runs within its own Ractor and processes Work objects sent to
it.

==== Implementation requirements

Your Worker subclass must:

. Inherit from `Fractor::Worker`
. Implement the `process(work)` method
. Return a `Fractor::WorkResult` object from the `process` method
. Handle both successful processing and error conditions

[source,ruby]
----
class MyWorker < Fractor::Worker
  def process(work)
    # Process the work

    if work.input < 0
      return Fractor::WorkResult.new(
        error: "Cannot process negative numbers",
        work: work
      )
    end

    # Normal processing...
    result = work.input * 2

    # Return a WorkResult
    Fractor::WorkResult.new(result: result, work: work)
  end
end
----


==== Error handling

The Worker class should handle two types of errors.


===== Handled errors

These are expected error conditions that your code explicitly checks for.

[source,ruby]
----
def process(work)
  if work.input < 0
    return Fractor::WorkResult.new(
      error: "Cannot process negative numbers",
      work: work
    )
  end

  # Normal processing...
  Fractor::WorkResult.new(result: calculated_value, work: work)
end
----

===== Unexpected errors caught by rescue

These are unexpected exceptions that may occur during processing. You should
catch these and convert them into error results.

[source,ruby]
----
def process(work)
  # Processing that might raise exceptions
  result = complex_calculation(work.input)

  Fractor::WorkResult.new(result: result, work: work)
rescue StandardError => e
  # Catch and convert any unexpected exceptions to error results
  Fractor::WorkResult.new(error: "An unexpected error occurred: #{e.message}", work: work)
end
----

[TIP]
====
* Keep the `process` method focused on a single responsibility
* Use meaningful error messages that help diagnose issues
* Consider adding logging within the `process` method for debugging
* Ensure all paths return a valid `WorkResult` object
====

=== WorkResult class

==== Purpose and responsibilities

The `Fractor::WorkResult` class is a container that holds either the successful
result of processing or an error message, along with a reference to the original
work item.

==== Creating results

To create a successful result:

[source,ruby]
----
# For successful processing
Fractor::WorkResult.new(result: calculated_value, work: work_object)
----

To create an error result:

[source,ruby]
----
# For error conditions
Fractor::WorkResult.new(error: "Error message", work: work_object)
----

==== Checking result status

You can check if a result was successful:

[source,ruby]
----
if work_result.success?
  # Handle successful result
  processed_value = work_result.result
else
  # Handle error
  error_message = work_result.error
end
----

==== Accessing original work

The original work item is always available:

[source,ruby]
----
original_work = work_result.work
input_value = original_work.input
----

=== ResultAggregator class

==== Purpose and responsibilities

The `Fractor::ResultAggregator` collects and organizes all results from the
workers, separating successful results from errors.

Completed work results may be order independent or order dependent.

* For order independent results, the results may be utilized (popped) as they
are received.

* For order dependent results, the results are aggregated in the order they
are received. The order of results is important for re-assembly or
further processing.

* For results that require aggregation, the `ResultsAggregator` is used to determine
whether the results are completed, which signify that all work items have
been processed and ready for further processing.


==== Accessing results

To access successful results:

[source,ruby]
----
# Get all successful results
successful_results = supervisor.results.results

# Extract just the result values
result_values = successful_results.map(&:result)
----

To access errors:

[source,ruby]
----
# Get all error results
error_results = supervisor.results.errors

# Extract error messages
error_messages = error_results.map(&:error)

# Get the work items that failed
failed_work_items = error_results.map(&:work)
----


[TIP]
====
* Check both successful results and errors after processing completes
* Consider implementing custom reporting based on the aggregated results
====


=== WrappedRactor class

==== Purpose and responsibilities

The `Fractor::WrappedRactor` class manages an individual Ruby Ractor, handling
the communication between the Supervisor and the Worker instance running inside
the Ractor.

==== Usage notes

This class is primarily used internally by the Supervisor, but understanding its
role helps with debugging:

* Each WrappedRactor creates and manages one Ractor
* The Worker instance lives inside the Ractor
* Work items are sent to the Ractor via the WrappedRactor's `send` method
* Results are yielded back to the Supervisor

==== Error propagation

The WrappedRactor handles error propagation in two ways:

. Errors from the Worker's `process` method are wrapped in a WorkResult and
  yielded back
. Unexpected errors in the Ractor itself are caught and logged


=== Supervisor class

==== Purpose and responsibilities

The `Fractor::Supervisor` class orchestrates the entire framework, managing
worker Ractors, distributing work, and collecting results.

==== Configuration options

When creating a Supervisor, you can configure:

[source,ruby]
----
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    # Pool 1 - for general data processing
    { worker_class: MyWorker, num_workers: 4 },

    # Pool 2 - for specialized image processing
    { worker_class: ImageWorker, num_workers: 2 }
  ],
  continuous_mode: false      # Optional: Run in continuous mode (default: false)
)
----

==== Worker auto-detection

Fractor automatically detects the number of available processors on your system
and uses that value when `num_workers` is not specified. This provides optimal
resource utilization across different deployment environments without requiring
manual configuration.

[source,ruby]
----
# Auto-detect number of workers (recommended for most cases)
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker }  # Will use number of available processors
  ]
)

# Explicitly set number of workers (useful for specific requirements)
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker, num_workers: 4 }  # Always use exactly 4 workers
  ]
)

# Mix auto-detection and explicit configuration
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: FastWorker },                    # Auto-detected
    { worker_class: HeavyWorker, num_workers: 2 }    # Explicitly 2 workers
  ]
)
----

The auto-detection uses Ruby's `Etc.nprocessors` which returns the number of
available processors. If detection fails for any reason, it falls back to 2
workers.

[TIP]
* Use auto-detection for portable code that adapts to different environments
* Explicitly set `num_workers` when you need precise control over resource usage
* Consider system load and other factors when choosing explicit values

==== Adding work

You can add work items individually or in batches:

[source,ruby]
----
# Add a single item
supervisor.add_work_item(MyWork.new(42))

# Add multiple items
supervisor.add_work_items([
  MyWork.new(1),
  MyWork.new(2),
  MyWork.new(3),
  MyWork.new(4),
  MyWork.new(5)
])

# Add items of different work types
supervisor.add_work_items([
  TextWork.new("Process this text"),
  ImageWork.new({ width: 800, height: 600 })
])
----

The Supervisor can handle any Work object that inherits from Fractor::Work.
Workers must check the type of Work they receive and process it accordingly.

==== Running and monitoring

To start processing:

[source,ruby]
----
# Start processing and block until complete
supervisor.run
----

The Supervisor automatically handles:

* Starting the worker Ractors
* Distributing work items to available workers
* Collecting results and errors
* Graceful shutdown on completion or interruption (Ctrl+C)


==== Accessing results

After processing completes:

[source,ruby]
----
# Get the ResultAggregator
aggregator = supervisor.results

# Check counts
puts "Processed #{aggregator.results.size} items successfully"
puts "Encountered #{aggregator.errors.size} errors"

# Access successful results
aggregator.results.each do |result|
  puts "Work item #{result.work.input} produced #{result.result}"
end

# Access errors
aggregator.errors.each do |error_result|
  puts "Work item #{error_result.work.input} failed: #{error_result.error}"
end
----

== Advanced usage patterns

=== Custom work distribution

For more complex scenarios, you might want to prioritize certain work items:

[source,ruby]
----
# Create Work objects for high priority items
high_priority_works = high_priority_items.map { |item| MyWork.new(item) }

# Add high-priority items first
supervisor.add_work_items(high_priority_works)

# Run with just enough workers for high-priority items
supervisor.run

# Create Work objects for lower priority items
low_priority_works = low_priority_items.map { |item| MyWork.new(item) }

# Add and process lower-priority items
supervisor.add_work_items(low_priority_works)
supervisor.run
----

=== Handling large datasets

For very large datasets, consider processing in batches:

[source,ruby]
----
large_dataset.each_slice(1000) do |batch|
  # Convert batch items to Work objects
  work_batch = batch.map { |item| MyWork.new(item) }

  supervisor.add_work_items(work_batch)
  supervisor.run

  # Process this batch's results before continuing
  process_batch_results(supervisor.results)
end
----


== Running a basic example

. Install the gem as described in the Installation section.

. Create a new Ruby file (e.g., `my_fractor_example.rb`) with your
implementation:

[source,ruby]
----
require 'fractor'

# Define your Work class
class MyWork < Fractor::Work
  def to_s
    "MyWork: #{@input}"
  end
end

# Define your Worker class
class MyWorker < Fractor::Worker
  def process(work)
    if work.input == 5
      # Return a Fractor::WorkResult for errors
      return Fractor::WorkResult.new(error: "Error processing work #{work.input}", work: work)
    end

    calculated = work.input * 2
    # Return a Fractor::WorkResult for success
    Fractor::WorkResult.new(result: calculated, work: work)
  end
end

# Create supervisor with a worker pool
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker, num_workers: 2 }
  ]
)

# Create Work objects
work_items = (1..10).map { |i| MyWork.new(i) }

# Add work items
supervisor.add_work_items(work_items)

# Run processing
supervisor.run

# Display results
puts "Results: #{supervisor.results.results.map(&:result).join(', ')}"
puts "Errors: #{supervisor.results.errors.map { |e| e.work.input }.join(', ')}"
----

. Run the example from your terminal:

[source,sh]
----
ruby my_fractor_example.rb
----

You will see output showing Ractors starting, receiving work, processing it, and
the final aggregated results, including any errors encountered. Press `Ctrl+C`
during execution to test the graceful shutdown.


== Continuous mode

=== General

Fractor provides a powerful feature called "continuous mode" that allows
supervisors to run indefinitely, processing work items as they arrive without
stopping after the initial work queue is empty.

=== Features

* *Non-stopping Execution*: Supervisors run indefinitely until explicitly stopped
* *On-demand Work*: Workers only process work when it's available
* *Resource Efficiency*: Workers idle when no work is available, without consuming excessive resources
* *Dynamic Work Addition*: New work can be added at any time through the work source callback
* *Graceful Shutdown*: Resources are properly cleaned up when the supervisor is stopped

Continuous mode is particularly useful for:

* *Chat servers*: Processing incoming messages as they arrive
* *Background job processors*: Handling tasks from a job queue
* *Real-time data processing*: Analyzing data streams as they come in
* *Web servers*: Responding to incoming requests in parallel
* *Monitoring systems*: Continuously checking system statuses

See the Chat Server example in the examples directory for a complete implementation of continuous mode.


=== Using continuous mode

==== Step 1. Create a supervisor with the `continuous_mode: true` option

[source,ruby]
----
supervisor = Fractor::Supervisor.new(
  worker_pools: [
    { worker_class: MyWorker, num_workers: 2 }
  ],
  continuous_mode: true  # Enable continuous mode
)
----

==== Step 2. Register a work source callback that provides new work on demand

[source,ruby]
----
supervisor.register_work_source do
  # Return nil or empty array if no work is available
  # Return a work item or array of work items when available
  items = get_next_work_items
  if items && !items.empty?
    # Convert to Work objects if needed
    items.map { |item| MyWork.new(item) }
  else
    nil
  end
end
----

==== Step 4. Run the supervisor in a non-blocking way

Typically in a background thread.

[source,ruby]
----
supervisor_thread = Thread.new { supervisor.run }
----

==== Step 4. Explicitly call `stop` on the supervisor to stop processing

[source,ruby]
----
supervisor.stop
supervisor_thread.join  # Wait for the supervisor thread to finish
----


== Process monitoring and logging

=== Status monitoring and health checks

The signals SIGUSR1 (or SIGBREAK on Windows) can be used for health checks.

When the signal is received, the supervisor prints its current status to
standard output.

[example]
====
Sending the signal:

Unix:

[source,sh]
----
# Send SIGUSR1 to the supervisor process
kill -USR1 <pid>
----

Windows:

[source,sh]
----
# Send SIGBREAK to the supervisor process
kill -BREAK <pid>
----

Output:

[source]
----
=== Fractor Supervisor Status ===
Mode: Continuous
Running: true
Workers: 4
Idle workers: 2
Queue size: 15
Results: 127
Errors: 3
----
====

==== Logging

Fractor supports logging of its operations to a specified log file.
To enable logging, set the `FRACTOR_LOG_FILE` environment variable to the
desired log file path before starting your application.

The log file will contain detailed information about the supervisor's
operations, including worker activity, work distribution, results, and errors.

To view the logs, you can use standard log monitoring tools or commands.

.Examples of accessing logs
[example]
====
[source,sh]
----
# Check if server is responsive (Unix/Linux/macOS)
kill -USR1 <pid> && tail -f /path/to/logs/server.log

# Monitor with systemd
systemctl status fractor-server
journalctl -u fractor-server -f

# Monitor with Docker
docker logs -f <container_id>
----
====


== Signal handling

=== General

Fractor provides production-ready signal handling for process control and
monitoring. The framework supports different signals depending on the operating
system, enabling graceful shutdown and runtime status monitoring.

=== Unix signals (Linux, macOS, Unix)

==== SIGINT (Ctrl+C)

Interactive interrupt signal for graceful shutdown.

Usage:

* Press `Ctrl+C` in the terminal running Fractor
* Behavior depends on mode:
** *Batch mode*: Stops immediately after current work completes
** *Continuous mode*: Initiates graceful shutdown

==== SIGTERM

Standard Unix termination signal, preferred for production deployments.

This ensures a graceful shutdown of the Fractor supervisor and its workers.

Usage:

[source,sh]
----
kill -TERM <pid>
# or simply
kill <pid>  # SIGTERM is the default
----

Typical signals from service managers:

* Systemd sends SIGTERM on `systemctl stop`
* Docker sends SIGTERM on `docker stop`
* Kubernetes sends SIGTERM during pod termination

[source,ini]
----
# Example systemd service
[Service]
ExecStart=/usr/bin/ruby /path/to/fractor_server.rb
KillMode=process
KillSignal=SIGTERM
TimeoutStopSec=30
----

==== SIGUSR1

Real-time status monitoring without stopping the process.

Usage:

[source,sh]
----
kill -USR1 <pid>
----

Output example:

[example]
====
[source]
----
=== Fractor Supervisor Status ===
Mode: Continuous
Running: true
Workers: 4
Idle workers: 2
Queue size: 15
Results: 127
Errors: 3
----
====

=== Windows signals

==== SIGBREAK (Ctrl+Break)

Windows alternative to SIGUSR1 for status monitoring.

Usage:

* Press `Ctrl+Break` in the terminal running Fractor
* Same output as SIGUSR1 on Unix

[NOTE]
SIGUSR1 is not available on Windows. Use `Ctrl+Break` instead for status
monitoring on Windows platforms.


=== Signal behavior by mode

==== Batch mode

In batch processing mode:

* SIGINT/SIGTERM: Stops immediately after current work completes
* SIGUSR1/SIGBREAK: Displays current status

==== Continuous mode

In continuous mode (long-running servers):

* SIGINT/SIGTERM: Graceful shutdown within ~2 seconds
** Stops accepting new work
** Completes in-progress work
** Cleans up resources
* SIGUSR1/SIGBREAK: Displays current status


== Example applications

=== General

The Fractor gem comes with several example applications that demonstrate various
patterns and use cases. Each example can be found in the `examples` directory of
the gem repository. Detailed descriptions for these are provided below.

=== Simple example

The Simple Example (link:examples/simple/[examples/simple/]) demonstrates the
basic usage of the Fractor framework. It shows how to create a simple Work
class, a Worker class, and a Supervisor to manage the processing of work items
in parallel. This example serves as a starting point for understanding how to
use Fractor.

Key features:

* Basic Work and Worker class implementation
* Simple Supervisor setup
* Parallel processing of work items
* Error handling and result aggregation
* Auto-detection of available processors
* Graceful shutdown on completion

=== Auto-detection example

The Auto-Detection Example (link:examples/auto_detection/[examples/auto_detection/])
demonstrates Fractor's automatic worker detection feature. It shows how to use
auto-detection, explicit configuration, and mixed approaches for controlling
the number of workers.

Key features:

* Automatic detection of available processors
* Comparison of auto-detection vs explicit configuration
* Mixed configuration with multiple worker pools
* Best practices for worker configuration
* Portable code that adapts to different environments

=== Hierarchical hasher

The Hierarchical Hasher example
(link:examples/hierarchical_hasher/[examples/hierarchical_hasher/]) demonstrates
how to use the Fractor framework to process a file in parallel by breaking it
into chunks, hashing each chunk independently, and then combining the results
into a final hash. This approach is useful for processing large files
efficiently.

Key features:

* Parallel data chunking for large files
* Independent processing of data segments
* Aggregation of results to form a final output

=== Multi-work type

The Multi-Work Type example
(link:examples/multi_work_type/[examples/multi_work_type/]) demonstrates how a
single Fractor supervisor and worker can handle multiple types of work items
(e.g., `TextWork` and `ImageWork`). The worker intelligently adapts its
processing strategy based on the class of the incoming work item.

Key features:

* Support for multiple `Fractor::Work` subclasses
* Polymorphic worker processing based on work type
* Unified workflow for diverse tasks

=== Pipeline processing

The Pipeline Processing example
(link:examples/pipeline_processing/[examples/pipeline_processing/]) implements a
multi-stage processing pipeline where data flows sequentially through a series
of transformations. The output of one stage becomes the input for the next, and
different stages can operate concurrently on different data items.

Key features:

* Sequential data flow through multiple processing stages
* Concurrent execution of different pipeline stages
* Data transformation at each step of the pipeline

=== Producer/subscriber

The Producer/Subscriber example
(link:examples/producer_subscriber/[examples/producer_subscriber/]) showcases a
multi-stage document processing system where initial work (processing a
document) can generate additional sub-work items (processing sections of the
document). This creates a hierarchical processing pattern.

Key features:

* Implementation of producer-consumer patterns
* Dynamic generation of sub-work based on initial processing
* Construction of hierarchical result structures

=== Scatter/gather

The Scatter/Gather example
(link:examples/scatter_gather/[examples/scatter_gather/]) illustrates how a
large task or dataset is broken down (scattered) into smaller, independent
subtasks. These subtasks are processed in parallel by multiple workers, and
their results are then collected (gathered) and combined to produce the final
output.

Key features:

* Distribution of a large task into smaller, parallelizable subtasks
* Concurrent processing of subtasks
* Aggregation of partial results into a final result

=== Specialized workers

The Specialized Workers example
(link:examples/specialized_workers/[examples/specialized_workers/]) demonstrates
creating distinct worker types, each tailored to handle specific kinds of tasks
(e.g., `ComputeWorker` for CPU-intensive operations and `DatabaseWorker` for
I/O-bound database interactions). This allows for optimized resource utilization
and domain-specific logic.

Key features:

* Creation of worker classes for specific processing domains
* Routing of work items to appropriately specialized workers
* Optimization of resources and logic per task type

=== Continuous chat server

==== General

The Continuous Chat Server examples demonstrate real-world implementations of
Fractor's continuous mode for building long-running, event-driven servers.

Two implementations are provided for comparison to highlight the benefits of
using Fractor for continuous processing.

==== Plain socket implementation

The plain socket implementation
(link:examples/continuous_chat_server/[examples/continuous_chat_server/])
provides a baseline chat server using plain TCP sockets without Fractor. This
serves as a comparison point to understand the benefits of using Fractor for
continuous processing.

==== Fractor-based implementation

The Fractor-based implementation
(link:examples/continuous_chat_fractor/[examples/continuous_chat_fractor/])
demonstrates how to build a production-ready chat server using Fractor's
continuous mode with advanced features.

Key features:

* *Continuous mode operation*: Server runs indefinitely processing messages as
  they arrive
* *Work source callbacks*: Dynamic work provision through registered callbacks
* *Graceful shutdown*: Production-ready signal handling (SIGINT, SIGTERM,
  SIGUSR1/SIGBREAK)
* *Idle worker management*: Efficient work distribution to available workers
* *Cross-platform support*: Works on Unix/Linux/macOS and Windows
* *Process monitoring*: Runtime status checking via signals
* *Thread coordination*: Supervisor thread, timer thread, and results processing
  thread

The implementation includes:

* `chat_common.rb`: Work and Worker class definitions for chat message
  processing
* `chat_server.rb`: Main server using Fractor continuous mode
* `simulate.rb`: Test client simulator
* `SIGNALS.md`: Comprehensive signal handling documentation

This example demonstrates production deployment patterns including:

* Systemd service integration
* Docker container deployment
* Process monitoring and health checks
* Graceful restart procedures

See link:examples/continuous_chat_fractor/README.adoc[the chat server README]
for detailed implementation documentation.


== Copyright and license

Copyright Ribose.

Licensed under the MIT License.
